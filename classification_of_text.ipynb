{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZiFVcabyX1",
        "colab_type": "text"
      },
      "source": [
        "##Реализация классификатора текста. \n",
        "\n",
        "Необходимо обучить модель для определения жанра фильма по его краткому описанию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu9Fy3R7b5cx",
        "colab_type": "text"
      },
      "source": [
        "### Используем TensorFlow 2.0\n",
        "\n",
        "Переключаемся на версию 2.0 (работает только в Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnq-IQdUYef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zI3nDdteAqz",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка библиотек\n",
        "TensorFlow должен иметь как минимум версию 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ew7HTbPpCJH",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weuyX007bVzL",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка и чтение данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti4P1MW6bZ0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# подключение к google диску\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqaYxWMWbaP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# рабочая директория; при первом запуске создадим директорию (если её еще не существует), \n",
        "# в противном случае надо заменить True на False \n",
        "if True:\n",
        "    !mkdir \"/content/drive/My Drive/Classificator_for_text\"\n",
        "%cd \"/content/drive/My Drive/Classificator_for_text\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFtBCgLtbbu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# загружаем данные (Genre_Classification_Dataset) в текущую рабочую директорию (Classificator_for_text)\n",
        "if True:\n",
        "    !7z x Genre_Classification_Dataset.7z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7z0VrbZfE-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# посмотрим на содержимое файлов \n",
        "descript = open('Genre_Classification_Dataset/description.txt',mode='rt')\n",
        "descript_res = descript.readlines()\n",
        "descript_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rovun-alfFNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = open('Genre_Classification_Dataset/train_data.txt',mode='rt')\n",
        "train_data = train_data.readlines()\n",
        "train_data[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zp_RvtHfFR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = open('Genre_Classification_Dataset/test_data.txt',mode='rt')\n",
        "test_data = test_data.readlines()\n",
        "test_data[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oByoT3np40Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_sol = open('Genre_Classification_Dataset/test_data_solution.txt',mode='rt')\n",
        "test_data_sol = test_data_sol.readlines()\n",
        "test_data_sol[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH_vOZKxUUp_",
        "colab_type": "text"
      },
      "source": [
        "### Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFRskpcO_8ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# преобразуем наши списковые данные в dataframe (трейновый датасет)\n",
        "\n",
        "id_list = []\n",
        "title = []\n",
        "genre = []\n",
        "descript = []\n",
        "\n",
        "for line in train_data: \n",
        "    line_row = line.split(':::')\n",
        "    id_list.append(line_row[0].strip())\n",
        "    title.append(line_row[1].strip())\n",
        "    genre.append(line_row[2].strip())\n",
        "    descript.append(line_row[3].strip())\n",
        "\n",
        "train_df = pd.DataFrame({'id': id_list, 'title': title, \n",
        "                         'genre': genre, 'descript': descript}, \n",
        "                        columns = ['id', 'title', 'genre', 'descript']) \n",
        "\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHw3m-rt_8Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# преобразуем наши списковые данные в dataframe (тестовый датасет)\n",
        "\n",
        "id_list = []\n",
        "title = []\n",
        "genre = []\n",
        "descript = []\n",
        "\n",
        "for line in test_data_sol: \n",
        "    line_row = line.split(':::')\n",
        "    id_list.append(line_row[0].strip())\n",
        "    title.append(line_row[1].strip())\n",
        "    genre.append(line_row[2].strip())\n",
        "    descript.append(line_row[3].strip())\n",
        "\n",
        "test_df = pd.DataFrame({'id': id_list, 'title': title, \n",
        "                        'genre': genre, 'descript': descript}, \n",
        "                       columns = ['id', 'title', 'genre', 'descript']) \n",
        "\n",
        "print(test_df.shape)\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yimrrHQa3qV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# жанры и их количество\n",
        "print('genres of train_df')\n",
        "print(train_df['genre'].unique())\n",
        "print(train_df['genre'].nunique())\n",
        "print('genres of test_df')\n",
        "print(test_df['genre'].unique())\n",
        "print(test_df['genre'].nunique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghK2M5Km3twB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genres_to_numb(dataframe): \n",
        "    dataframe['genre'] = dataframe['genre'].map({'drama': 0, \n",
        "                                                 'thriller': 1, \n",
        "                                                 'adult': 2, \n",
        "                                                 'documentary': 3, \n",
        "                                                 'comedy': 4, \n",
        "                                                 'crime': 5, \n",
        "                                                 'reality-tv': 6, \n",
        "                                                 'horror': 7, \n",
        "                                                 'sport': 8, \n",
        "                                                 'animation': 9, \n",
        "                                                 'action': 10, \n",
        "                                                 'fantasy': 11, \n",
        "                                                 'short': 12, \n",
        "                                                 'sci-fi': 13, \n",
        "                                                 'music': 14, \n",
        "                                                 'adventure': 15, \n",
        "                                                 'talk-show': 16, \n",
        "                                                 'western': 17, \n",
        "                                                 'family': 18, \n",
        "                                                 'mystery': 19, \n",
        "                                                 'history': 20, \n",
        "                                                 'news': 21, \n",
        "                                                 'biography': 22, \n",
        "                                                 'romance': 23, \n",
        "                                                 'game-show': 24, \n",
        "                                                 'musical': 25, \n",
        "                                                 'war': 26}).astype(int)\n",
        "\n",
        "# genres of train_df в числа (27 категорий!)\n",
        "genres_to_numb(train_df)\n",
        "\n",
        "# genres of test_df в числа (27 категорий!)\n",
        "genres_to_numb(test_df)\n",
        "\n",
        "# pd.series to array\n",
        "train_labels = train_df['genre'].to_numpy()\n",
        "test_labels = test_df['genre'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYMuSi864Akh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xeDlYZz4A8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH_GPdEIwg4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "# pd.series to array\n",
        "train_data = train_df['descript'].to_numpy()\n",
        "test_data = test_df['descript'].to_numpy()\n",
        "\n",
        "# tokenizer and vocab\n",
        "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
        "\n",
        "def tokenize_text_simple_regex(txt, min_token_size=4):\n",
        "    txt = txt.lower()\n",
        "    all_tokens = TOKEN_RE.findall(txt)\n",
        "    return [token for token in all_tokens if len(token) >= min_token_size]\n",
        "\n",
        "# токенизация корпуса \n",
        "def tokenize_corpus(texts, tokenizer=tokenize_text_simple_regex, **tokenizer_kwargs):\n",
        "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]\n",
        "\n",
        "# добавление фейкового токена \n",
        "def add_fake_token(word2id, token='<PAD>'):\n",
        "    word2id_new = {token: i + 1 for token, i in word2id.items()}\n",
        "    word2id_new[token] = 0\n",
        "    return word2id_new\n",
        "\n",
        "# тексты в токены \n",
        "def texts_to_token_ids(tokenized_texts, word2id):\n",
        "    return [[word2id[token] for token in text if token in word2id]\n",
        "            for text in tokenized_texts]\n",
        "\n",
        "\n",
        "def build_vocabulary(tokenized_texts, max_size=10000, max_doc_freq=0.8, \n",
        "                     min_count=5, pad_word=None):\n",
        "    word_counts = collections.defaultdict(int)\n",
        "    doc_n = 0\n",
        "\n",
        "    # посчитать количество документов, в которых употребляется каждое слово\n",
        "    # а также общее количество документов\n",
        "    for txt in tokenized_texts:\n",
        "        doc_n += 1\n",
        "        unique_text_tokens = set(txt)\n",
        "        for token in unique_text_tokens:\n",
        "            word_counts[token] += 1\n",
        "\n",
        "    # убрать слишком редкие и слишком частые слова\n",
        "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
        "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
        "\n",
        "    # отсортировать слова по убыванию частоты\n",
        "    sorted_word_counts = sorted(word_counts.items(),\n",
        "                                reverse=True,\n",
        "                                key=lambda pair: pair[1])\n",
        "\n",
        "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
        "    if pad_word is not None:\n",
        "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
        "\n",
        "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
        "    if len(word_counts) > max_size:\n",
        "        sorted_word_counts = sorted_word_counts[:max_size]\n",
        "\n",
        "    # нумеруем слова\n",
        "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
        "\n",
        "    # нормируем частоты слов\n",
        "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
        "\n",
        "    return word2id, word2freq\n",
        "\n",
        "# PAD_TOKEN = '__PAD__'\n",
        "# NUMERIC_TOKEN = '__NUMBER__'\n",
        "# NUMERIC_RE = re.compile(r'^([0-9.,e+\\-]+|[mcxvi]+)$', re.I)\n",
        "\n",
        "# def replace_number_nokens(tokenized_texts):\n",
        "#     return [[token if not NUMERIC_RE.match(token) else NUMERIC_TOKEN for token in text]\n",
        "#             for text in tokenized_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QizarLUR2PME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokenized = tokenize_corpus(train_data)\n",
        "test_tokenized = tokenize_corpus(test_data)\n",
        "\n",
        "print(' '.join(train_tokenized[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJv9pPg52W8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, \n",
        "                                             max_doc_freq=0.8, \n",
        "                                             min_count=5, \n",
        "                                             pad_word='<PAD>')\n",
        "\n",
        "UNIQUE_WORDS_N = len(vocabulary)\n",
        "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
        "print(list(vocabulary.items())[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8rsKnBWUg6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(word_doc_freq, bins=20)\n",
        "plt.title('Распределение относительных частот слов')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYNo7Kgsd4OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numbers of tokens\n",
        "train_token_ids = texts_to_token_ids(train_tokenized, vocabulary)\n",
        "test_token_ids = texts_to_token_ids(test_tokenized, vocabulary)\n",
        "\n",
        "print('\\n'.join(' '.join(str(t) for t in sent)\n",
        "                for sent in train_token_ids[:10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exvoQKE-d4L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist([len(s) for s in train_token_ids], bins=20);\n",
        "plt.title('Гистограмма длин предложений');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzLoXBfbGWJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LEN = 256 # Финальная длина последовательности\n",
        "\n",
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    train_token_ids,\n",
        "    value=vocabulary[\"<PAD>\"],\n",
        "    padding='post',\n",
        "    maxlen=MAX_SEQ_LEN)\n",
        "\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    test_token_ids,\n",
        "    value=vocabulary[\"<PAD>\"],\n",
        "    padding='post',\n",
        "    maxlen=MAX_SEQ_LEN)\n",
        "\n",
        "print(\"Length examples: {}\".format([len(train_data[0]), len(train_data[1])]))\n",
        "print('=====================================')\n",
        "print(\"Entry example: {}\".format(train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DFY3ibTUUqO",
        "colab_type": "text"
      },
      "source": [
        "### Создание модели "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xpKOoWgu-llD",
        "colab": {}
      },
      "source": [
        "EMB_SIZE = 32 # Размер векторного представления (эмбеддинга) \n",
        "    \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(UNIQUE_WORDS_N, 32),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(27, activation=tf.nn.softmax),\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8J112EGUUqS",
        "colab_type": "text"
      },
      "source": [
        "### Подготовка модели к обучению\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mr0GP-cQ-llN",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTE1uIbSUUqV",
        "colab_type": "text"
      },
      "source": [
        "### Разбиение на обучающую и валидационную выборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NpcXY9--llS",
        "colab": {}
      },
      "source": [
        "# валидационная выборка составит около 25% \n",
        "border_split = int(train_df.shape[0]) - 13550\n",
        "\n",
        "partial_x_train = train_data[:border_split]\n",
        "x_val = train_data[border_split:]\n",
        "partial_y_train = train_labels[:border_split]\n",
        "y_val = train_labels[border_split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFmKIMq0UUqY",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tXSGrjWZ-llW",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 26\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo3qpeqTUUqb",
        "colab_type": "text"
      },
      "source": [
        "### Оценка качества на тестовом датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOMKywn4zReN",
        "outputId": "b28a6e00-4956-4627-eb16-8fca0d4c6a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('Test loss: {:.4f}'.format(results[0]))\n",
        "print('Test accuracy: {:.2f} %'.format(results[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1694/1694 [==============================] - 5s 3ms/step - loss: 1.6667 - acc: 0.5381\n",
            "Test loss: 1.6667\n",
            "Test accuracy: 53.81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70XE364ur-5i",
        "colab_type": "text"
      },
      "source": [
        "Accuracy на тестовой выборке составляет больше 50%, что является очень хорошим результатом, т.к. у нас классификация идет на 27 категорий. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEZH1SneWpPu",
        "colab_type": "text"
      },
      "source": [
        "### Графики лосса и точности на обучающем и валидационном датасетах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGoYf2Js-lle",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "epochs = range(1, len(history.history['acc']) + 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, history.history['loss'], 'bo', label='Training loss')\n",
        "plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, history.history['acc'], 'bo', label='Training acc')\n",
        "plt.plot(epochs, history.history['val_acc'], 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvhbvwZ5cES8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}